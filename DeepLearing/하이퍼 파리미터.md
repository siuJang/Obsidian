- **학습률 (Learning Rate)**
    
    - **정의**: 학습 과정에서 각 반복마다 모델의 가중치를 얼마나 조정할지 결정하는 매개변수입니다.
    - **영향**: 학습률이 너무 작으면 학습 속도가 느리고, 너무 크면 발산할 수 있습니다.
- **배치 크기 (Batch Size)**
    
    - **정의**: 한 번의 반복에서 처리할 데이터의 샘플 개수를 결정하는 매개변수입니다.
    - **영향**: 배치 크기가 작으면 더 많은 업데이트가 가능하지만, 학습 속도가 느려질 수 있습니다. 큰 배치 크기는 메모리 사용량이 늘어날 수 있습니다.
- **에포크 수 (Number of Epochs)**
    
    - **정의**: 전체 데이터셋을 한 번 학습하는 주기를 결정하는 매개변수입니다.
    - **영향**: 에포크 수가 너무 적으면 모델이 충분히 학습하지 못할 수 있으며, 너무 많으면 과적합의 위험이 있을 수 있습니다.
- **정규화 매개변수 (Regularization Parameters)**
    
    - **정의**: L1 정규화(l1 regularization)나 L2 정규화(l2 regularization)와 같은 정규화의 강도를 결정하는 매개변수입니다.
    - **영향**: 정규화 매개변수가 클수록 모델의 복잡도가 줄어들고, 일반화 성능이 향상될 수 있습니다.
- **드롭아웃 비율 (Dropout Rate)**
    
    - **정의**: 신경망에서 무작위로 일부 뉴런을 제거하여 과적합을 방지하기 위한 기법의 비율을 결정하는 매개변수입니다.
    - **영향**: 드롭아웃 비율이 클수록 모델의 일반화 성능이 향상될 수 있지만, 너무 높으면 언더피팅(underfitting)이 발생할 수 있습니다.
- **초기화 방법 (Initialization Methods)**
    
    - **정의**: 신경망 가중치 초기화 방법을 결정하는 매개변수입니다.
    - **영향**: 초기화 방법이 모델 학습의 속도와 최종 성능에 중요한 영향을 미칠 수 있습니다.
- **옵티마이저 (Optimizer) 및 관련 매개변수**
    
    - **정의**: 경사 하강법(Gradient Descent) 방법 중 하나를 선택하고, 그 옵티마이저의 매개변수들을 설정하는 것입니다 (예: 모멘텀, 아다그라드, 아담 등).
    - **영향**: 옵티마이저의 선택과 설정에 따라 학습 속도와 최종 모델 성능에 영향을 줄 수 있습니다.